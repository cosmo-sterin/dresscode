{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results 3    \n",
    "The structure of our photos is quite simple.   \n",
    "Each photo of the catalogue is divided into tiles on a 4x5 grid, the useful information is to be found in two tiles, (1,2) and (2,2).\n",
    "The same kind of heuristic is used to isolate information with queries.    \n",
    "Thus each catalogue item and query give 2 feature vectors.  \n",
    "For a query each catalogue item is ranked according the best matcher among these 4 feature vectors.    \n",
    "It gives a **71%** 10-accuracy result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import io\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "to_ignore = [53,89,110,120,127,131,144,167,159,190]\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "### Catalogue Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 items in the catalogue\n"
     ]
    }
   ],
   "source": [
    "cat_dir = 'db/robes/cat/'\n",
    "list_cat = [cat_dir+f for f in os.listdir(cat_dir) if re.search('jpg|JPG', f)]\n",
    "list_cat = list(filter(lambda x: \"_0\" in x, list_cat))\n",
    "list_cat.sort(key=lambda x: int(x.split(\"/\")[-1].split(\"_\")[0]))\n",
    "print(str(len(list_cat))+\" items in the catalogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 queries to perform\n"
     ]
    }
   ],
   "source": [
    "### Query Images\n",
    "query_dir = 'db/robes/mod/'\n",
    "list_query = [query_dir+f for f in os.listdir(query_dir) if re.search('jpg|JPG', f)]\n",
    "list_query.sort(key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "print(str(len(list_query))+\" queries to perform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "def create_graph():\n",
    "    with gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "create_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This routine operates the cropings before extracting features\n",
    "def extract_features(list_images,mod=True,p=False):\n",
    "    nb_features = 2048\n",
    "    features = []\n",
    "\n",
    "    next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\n",
    "    for ind, image in enumerate(list_images):\n",
    "        #Getting rid of ignored\n",
    "        if ind in to_ignore:\n",
    "            mini_features = []\n",
    "            \n",
    "            for i in range(2):\n",
    "                mini_features.append(np.zeros(nb_features))\n",
    "            features.append(mini_features[:])\n",
    "            if p:\n",
    "                for (i,x) in enumerate(features[-1]):\n",
    "                    print(i,x)\n",
    "            continue\n",
    "        if (ind%1 == 0) and p:\n",
    "            print('Processing %s...' % (image))\n",
    "        if not gfile.Exists(image):\n",
    "            tf.logging.fatal('File does not exist %s', image)\n",
    "\n",
    "        image_data = gfile.FastGFile(image, 'rb').read()\n",
    "        image_data_tensor = tf.image.decode_jpeg(image_data)\n",
    "        \n",
    "        #Getting all the crops\n",
    "        mini_features = []\n",
    "        \n",
    "        if mod:\n",
    "            of_y = int(sess.run(image_data_tensor).shape[0]/10)\n",
    "            of_x = int(sess.run(image_data_tensor).shape[1]/11)\n",
    "            for i in range(10):\n",
    "                if i in [0,1,2,3,6,7,8,9]:\n",
    "                    continue\n",
    "                for j in range(11):\n",
    "                    if j != 5:\n",
    "                        continue\n",
    "        \n",
    "                    image_data_croped  = tf.image.crop_to_bounding_box(image_data_tensor,i*of_y,j*of_x,of_y,of_x)\n",
    "                    image_data_modified = tf.image.encode_jpeg(image_data_croped)\n",
    "                    predictions = sess.run(next_to_last_tensor,{'DecodeJpeg/contents:0': sess.run(image_data_modified)})\n",
    "                    mini_features.append(np.squeeze(predictions))\n",
    "        else:\n",
    "            of_y = int(sess.run(image_data_tensor).shape[0]/4)\n",
    "            of_x = int(sess.run(image_data_tensor).shape[1]/5)\n",
    "        \n",
    "            for i in range(4):\n",
    "                if i == 0 or i == 3:\n",
    "                    continue\n",
    "                for j in range(5):\n",
    "                    if j == 0 or j == 4 or j == 1 or j == 3:\n",
    "                        continue\n",
    "                    image_data_croped  = tf.image.crop_to_bounding_box(image_data_tensor,i*of_y,j*of_x,of_y,of_x)\n",
    "                    image_data_modified = tf.image.encode_jpeg(image_data_croped)\n",
    "                    predictions = sess.run(next_to_last_tensor,{'DecodeJpeg/contents:0': sess.run(image_data_modified)})\n",
    "                    mini_features.append(np.squeeze(predictions))\n",
    "        \n",
    "        features.append(mini_features[:])\n",
    "        if p:\n",
    "            for (i,x) in enumerate(features[-1]):\n",
    "                print(i,x)\n",
    "    print(\"Done\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "cat_features = extract_features(list_cat,mod=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "query_features = extract_features(list_query,mod=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 210)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Safety check\n",
    "len(cat_features),len(query_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Results\n",
    "For each queries, the best matching items in the catalogue, according to cosine similarity, are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "def sim(vecA,vecB):\n",
    "    return vecA.dot(vecB)\n",
    "#Perform the best matching retrieval\n",
    "#For a given query and a given object the matching score is the max\n",
    "#of similiraties over the 4 corresponding vectors in memory.\n",
    "#Accuracy: what it means to match, by default it is to be in the top 10 closest\n",
    "#p: print debug\n",
    "def query(i_query,accuracy=10,p=False):\n",
    "    sim_vec = []\n",
    "    for i in range(len(cat_features)):\n",
    "        M = 0.0\n",
    "        for k in range(2):\n",
    "            for l in range(2):\n",
    "                M = max(M,sim(query_features[i_query][k],cat_features[i][l]))\n",
    "        sim_vec.append(M)\n",
    "    sim_vec = np.array(sim_vec)\n",
    "    arg_s = sim_vec.argsort()[:-accuracy:-1]\n",
    "    if p:\n",
    "        print(i_query,arg_s,[sim_vec[i] for i in arg_s], sim_vec[i_query])\n",
    "    return i_query in arg_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalization before querying\n",
    "for i in range(len(cat_features)):\n",
    "    if not i in to_ignore:\n",
    "        for j in range(2):\n",
    "            cat_features[i][j] /= np.linalg.norm(cat_features[i][j])\n",
    "            query_features[i][j] /= np.linalg.norm(query_features[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting result while getting rid of ignored val\n",
    "matching_frac = 0.0\n",
    "ignored = 0\n",
    "for i in range(len(cat_features)):\n",
    "    if not i in to_ignore:\n",
    "        matching_frac += query(i)\n",
    "    else:\n",
    "        ignored += 1\n",
    "matching_frac /= (len(cat_features)-ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This method gives a 71.0 10-accuracy success\n"
     ]
    }
   ],
   "source": [
    "print(\"This method gives a \"+str(matching_frac*100)+\" 10-accuracy success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion and Perspectives\n",
    "This **hand-made** heuristic to crop the images of this dataset can be justified in our application setting:   \n",
    "-The retailer can make the relevant crops when it builds its catalogue    \n",
    "-The user can zoom over what interests him when he make the query    \n",
    "However this example emphasizes **the importance of selecting relevant part of the clothes**, wether it is done by hand or automatically.   \n",
    "Methods in the spirit of \"Points of Interets\" as used in SIFT descriptors could be used to get rid of this hand-crafted dataset\n",
    "specific part of the method.    \n",
    "Enventually to handle more crops efficiently in memory, techniques such as **memory vectors** could be used.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
