{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results 2\n",
    "In order to get better result queries are croped on their center with a (500,500) window.   \n",
    "It gives a **51%** 10-accuracy result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "to_ignore = [53,89,110,120,127,131,144,167,159,190]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "### Catalogue Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 items in the catalogue\n"
     ]
    }
   ],
   "source": [
    "cat_dir = 'db/robes/cat/'\n",
    "list_cat = [cat_dir+f for f in os.listdir(cat_dir) if re.search('jpg|JPG', f)]\n",
    "list_cat = list(filter(lambda x: \"_0\" in x, list_cat))\n",
    "list_cat.sort(key=lambda x: int(x.split(\"/\")[-1].split(\"_\")[0]))\n",
    "print(str(len(list_cat))+\" items in the catalogue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 queries to perform\n"
     ]
    }
   ],
   "source": [
    "### Query Images\n",
    "query_dir = 'db/robes/mod/'\n",
    "list_query = [query_dir+f for f in os.listdir(query_dir) if re.search('jpg|JPG', f)]\n",
    "list_query.sort(key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "print(str(len(list_cat))+\" queries to perform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "def create_graph():\n",
    "    with gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "create_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the feature vectors corresponding to a list of image\n",
    "#This function does the centered crop\n",
    "def extract_features(list_images,p=False):\n",
    "    nb_features = 2048\n",
    "    features = np.zeros((len(list_images),nb_features))\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\n",
    "    for ind, image in enumerate(list_images):\n",
    "        if ind in to_ignore:\n",
    "            if p:\n",
    "                print('Ignore item %d'%(ind))\n",
    "                print('Feature vector:', features[ind,:])\n",
    "            continue\n",
    "        if (ind%1 == 0) and p:\n",
    "            print('Processing %s...' % (image))\n",
    "        if not gfile.Exists(image):\n",
    "            tf.logging.fatal('File does not exist %s', image)\n",
    "\n",
    "        image_data = gfile.FastGFile(image, 'rb').read()\n",
    "        image_data_tensor = tf.image.decode_jpeg(image_data)\n",
    "        #Croping operation\n",
    "        image_data_croped = tf.image.resize_image_with_crop_or_pad(image_data_tensor,  500, 500)\n",
    "        image_data_modified = tf.image.encode_jpeg(image_data_croped)\n",
    "        predictions = sess.run(next_to_last_tensor,{'DecodeJpeg/contents:0': sess.run(image_data_modified)})\n",
    "        features[ind,:] = np.squeeze(predictions)\n",
    "        if p:\n",
    "            print('Feature vector:', features[ind,:])\n",
    "        labels.append(io.BytesIO(image_data))\n",
    "    print(\"Done\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "cat_features = extract_features(list_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "query_features = extract_features(list_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 210)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Safety check\n",
    "len(cat_features),len(query_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Results\n",
    "For each queries, the best matching items in the catalogue, according to cosine similarity, are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "def sim(vecA,vecB):\n",
    "    return vecA.dot(vecB)\n",
    "#Perform the best matching retrieval\n",
    "#Accuracy: what it means to match, by default it is to be in the top 10 closest\n",
    "#p: print debug\n",
    "def query(i_query,accuracy=10,p=False):\n",
    "    sim_vec = []\n",
    "    for i in range(len(cat_features)):\n",
    "        sim_vec.append(sim(query_features[i_query],cat_features[i]))\n",
    "    sim_vec = np.array(sim_vec)\n",
    "    arg_s = sim_vec.argsort()[:-accuracy:-1]\n",
    "    if p:\n",
    "        print(i_query,arg_s,[sim_vec[i] for i in arg_s], sim_vec[i_query])\n",
    "    return i_query in arg_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalization before querying\n",
    "for i in range(len(cat_features)):\n",
    "    if not i in to_ignore:\n",
    "        cat_features[i] /= np.linalg.norm(cat_features[i])\n",
    "        query_features[i] /= np.linalg.norm(query_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting result while getting rid of ignored val\n",
    "matching_frac = 0.0\n",
    "ignored = 0\n",
    "for i in range(len(cat_features)):\n",
    "    if not i in to_ignore:\n",
    "        matching_frac += query(i)\n",
    "    else:\n",
    "        ignored += 1\n",
    "matching_frac /= (len(cat_features)-ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This method gives a 51.0 10-accuracy success\n"
     ]
    }
   ],
   "source": [
    "print(\"This method gives a \"+str(matching_frac*100)+\" 10-accuracy success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is better but it may not look were it should either, maybe the relevant information is not in the center of the query. Also the catalogue item should be croped for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
